{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Covariance 3D Estimation\n\nThis script illustrates the example of Covariance 3D estimation using simulation images\ngenerated from Gaussian blob volumes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom scipy.cluster.vq import kmeans2\n\nfrom aspire.basis import FBBasis3D\nfrom aspire.covariance import CovarianceEstimator\nfrom aspire.denoising import src_wiener_coords\nfrom aspire.noise import WhiteNoiseEstimator\nfrom aspire.operators import RadialCTFFilter\nfrom aspire.reconstruction import MeanEstimator\nfrom aspire.source.simulation import Simulation\nfrom aspire.utils import eigs\nfrom aspire.utils.random import Random\nfrom aspire.volume import LegacyVolume, Volume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Simulation Object\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specify parameters\nimg_size = 8  # image size in square\nnum_imgs = 1024  # number of images\nnum_eigs = 16  # number of eigen-vectors to keep\ndtype = np.float32\n\n# Generate a ``Volume`` object for use in the simulation. Here we use a ``LegacyVolume`` and\n# set C = 3 to generate 3 unique random volumes.\nvols = LegacyVolume(\n    L=img_size,\n    C=3,\n    dtype=dtype,\n    pixel_size=10,\n).generate()\n\n# Create a simulation object with specified filters\nsim = Simulation(\n    L=img_size,\n    n=num_imgs,\n    vols=vols,\n    unique_filters=[RadialCTFFilter(defocus=d) for d in np.linspace(1.5e4, 2.5e4, 7)],\n    dtype=dtype,\n)\n\n# The Simulation object was created using 3 volumes.\nnum_vols = sim.C\n\n# Specify the normal FB basis method for expending the 2D images\nbasis = FBBasis3D(img_size)\n\n# Estimate the noise variance. This is needed for the covariance estimation step below.\nnoise_estimator = WhiteNoiseEstimator(sim, batch_size=500)\nnoise_variance = noise_estimator.estimate()\nprint(f\"Noise Variance = {noise_variance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimate Mean Volume and Covariance\n\nEstimate the mean. This uses conjugate gradient on the normal equations for\nthe least-squares estimator of the mean volume. The mean volume is represented internally\nusing the basis object, but the output is in the form of an\nL-by-L-by-L array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_estimator = MeanEstimator(sim, basis=basis)\nmean_est = mean_estimator.estimate()\n\n# Passing in a mean_kernel argument to the following constructor speeds up some calculations\ncovar_estimator = CovarianceEstimator(\n    sim, basis=basis, mean_kernel=mean_estimator.kernel\n)\ncovar_est = covar_estimator.estimate(mean_est, noise_variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Top Eigenpairs to Form a Basis\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Extract the top eigenvectors and eigenvalues of the covariance estimate.\n# Since we know the population covariance is low-rank, we are only interested\n# in the top eigenvectors.\n\neigs_est, lambdas_est = eigs(covar_est, num_eigs)\n\n# Eigs returns column-major, so we transpose and construct a volume.\neigs_est = Volume(np.transpose(eigs_est, (3, 0, 1, 2)), pixel_size=vols.pixel_size)\n\n# Truncate the eigendecomposition. Since we know the true rank of the\n# covariance matrix, we enforce it here.\n\neigs_est_trunc = eigs_est[: num_vols - 1]\nlambdas_est_trunc = lambdas_est[: num_vols - 1, : num_vols - 1]\n\n# Estimate the coordinates in the eigenbasis. Given the images, we find the\n# coordinates in the basis that minimize the mean squared error, given the\n# (estimated) covariances of the volumes and the noise process.\ncoords_est = src_wiener_coords(\n    sim, mean_est, eigs_est_trunc, lambdas_est_trunc, noise_variance\n)\n\n# Cluster the coordinates using k-means. Again, we know how many volumes\n# we expect, so we can use this parameter here. Typically, one would take\n# the number of clusters to be one plus the number of eigenvectors extracted.\n\n# Since kmeans2 relies on randomness for initialization, important to push random seed to context manager here.\nwith Random(0):\n    centers, vol_idx = kmeans2(coords_est.T, num_vols)\n    centers = centers.squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Evaluation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Evaluate performance of mean estimation.\n\nmean_perf = sim.eval_mean(mean_est)\n\n\n# Evaluate performance of covariance estimation. We also evaluate the truncated\n# eigendecomposition. This is expected to be a closer approximation since it\n# imposes an additional low-rank condition on the estimate.\n\ncovar_perf = sim.eval_covar(covar_est)\neigs_perf = sim.eval_eigs(eigs_est_trunc, lambdas_est_trunc)\n\n# Evaluate clustering performance.\n\nclustering_accuracy = sim.eval_clustering(vol_idx)\n\n# Assign the cluster centroids to the different images. Since we expect a discrete distribution of volumes\n# (and therefore of coordinates), we assign the centroid coordinate to each image that belongs to that cluster.\n# Evaluate the coordinates estimated\n\nclustered_coords_est = centers[vol_idx]\ncoords_perf = sim.eval_coords(mean_est, eigs_est_trunc, clustered_coords_est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Output estimated covariance spectrum.\n\nprint(f\"Population Covariance Spectrum = {np.diag(lambdas_est)}\")\n\n\n# Output performance results.\n\nprint(f'Mean (rel. error) = {mean_perf[\"rel_err\"]}')\nprint(f'Mean (correlation) = {mean_perf[\"corr\"]}')\nprint(f'Covariance (rel. error) = {covar_perf[\"rel_err\"]}')\nprint(f'Covariance (correlation) = {covar_perf[\"corr\"]}')\nprint(f'Eigendecomposition (rel. error) = {eigs_perf[\"rel_err\"]}')\nprint(f\"Clustering (accuracy) = {clustering_accuracy}\")\nprint(f'Coordinates (mean rel. error) = {coords_perf[\"rel_err\"]}')\nprint(f'Coordinates (mean correlation) = {np.mean(coords_perf[\"corr\"])}')\n\n# Basic Check\nassert covar_perf[\"rel_err\"] <= 0.80\nassert np.mean(coords_perf[\"corr\"]) >= 0.97\nassert clustering_accuracy >= 0.99"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}