{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Abinitio Pipeline - Simulated Data\n\nThis notebook introduces a selection of\ncomponents corresponding to generating realistic\nsimulated cryo-EM data and running key ASPIRE-Python\nAbinitio model components as a pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\nFirst import some of the usual suspects.\nIn addition, import some classes from\nthe ASPIRE package that will be used throughout this experiment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom aspire.abinitio import CLSync3N\nfrom aspire.denoising import DefaultClassAvgSource, DenoisedSource, DenoiserCov2D\nfrom aspire.downloader import emdb_2660\nfrom aspire.noise import AnisotropicNoiseEstimator, CustomNoiseAdder\nfrom aspire.operators import FunctionFilter, RadialCTFFilter\nfrom aspire.reconstruction import MeanEstimator\nfrom aspire.source import OrientedSource, Simulation\nfrom aspire.utils import mean_aligned_angular_distance\n\nlogger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\nSome example simulation configurations.\nSmall sim: img_size 32, num_imgs 10000, n_classes 1000, n_nbor 10\nMedium sim: img_size 64, num_imgs 20000, n_classes 2000, n_nbor 10\nLarge sim: img_size 129, num_imgs 30000, n_classes 2000, n_nbor 20\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "interactive = True  # Draw blocking interactive plots?\ndo_cov2d = False  # Use CWF coefficients\nimg_size = 32  # Downsample the volume to a desired resolution\nnum_imgs = 10000  # How many images in our source.\nn_classes = 1000  # How many class averages to compute.\nn_nbor = 10  # How many neighbors to stack\nnoise_variance = 5e-7  # Set a target noise variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulation Data\nStart with the hi-res volume map EMDB-2660 sourced from EMDB,\nhttps://www.ebi.ac.uk/emdb/EMD-2660, and dowloaded via ASPIRE's downloader utility.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "og_v = emdb_2660()\nlogger.info(\"Original volume map data\" f\" shape: {og_v.shape} dtype:{og_v.dtype}\")\n\n\n# Then create a filter based on that variance\n# This is an example of a custom noise profile\ndef noise_function(x, y):\n    alpha = 1\n    beta = 1\n    # White\n    f1 = noise_variance\n    # Violet-ish\n    f2 = noise_variance * (x * x + y * y) / (img_size * img_size)\n    return (alpha * f1 + beta * f2) / 2.0\n\n\ncustom_noise = CustomNoiseAdder(noise_filter=FunctionFilter(noise_function))\n\nlogger.info(\"Initialize CTF filters.\")\n# Create some CTF effects\npixel_size = og_v.pixel_size  # Pixel size (in angstroms)\nvoltage = 200  # Voltage (in KV)\ndefocus_min = 1.5e4  # Minimum defocus value (in angstroms)\ndefocus_max = 2.5e4  # Maximum defocus value (in angstroms)\ndefocus_ct = 7  # Number of defocus groups.\nCs = 2.0  # Spherical aberration\nalpha = 0.1  # Amplitude contrast\n\n# Create filters\nctf_filters = [\n    RadialCTFFilter(pixel_size, voltage, defocus=d, Cs=2.0, alpha=0.1)\n    for d in np.linspace(defocus_min, defocus_max, defocus_ct)\n]\n\n# Finally create the Simulation\nsrc = Simulation(\n    n=num_imgs,\n    vols=og_v,\n    noise_adder=custom_noise,\n    unique_filters=ctf_filters,\n)\n\n# Downsample\nsrc = src.downsample(img_size).cache()\n\n# Peek\nif interactive:\n    src.images[:10].show()\n\n# Use phase_flip to attempt correcting for CTF.\nlogger.info(\"Perform phase flip to input images.\")\nsrc = src.phase_flip()\n\n# Estimate the noise and `Whiten` based on the estimated noise\naiso_noise_estimator = AnisotropicNoiseEstimator(src)\nsrc = src.whiten(aiso_noise_estimator)\n\n# Cache to memory for some speedup\nsrc = src.cache()\n\n# Plot the noise profile for inspection\nif interactive:\n    plt.imshow(aiso_noise_estimator.filter.evaluate_grid(img_size))\n    plt.show()\n\n# Peek, what do the whitened images look like...\nif interactive:\n    src.images[:10].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: CWF Denoising\n\nOptionally generate an alternative source that is denoised with `cov2d`,\nthen configure a customized aligner. This allows the use of CWF denoised\nimages for classification, but stacks the original images for averages\nused in the remainder of the reconstruction pipeline.\n\nIn this example, this behavior is controlled by the `do_cov2d` boolean variable.\nWhen disabled, the original src and default aligner is used.\nIf you will not be using cov2d,\nyou may remove this code block and associated variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classification_src = src\nif do_cov2d:\n    # Use CWF denoising\n    cwf_denoiser = DenoiserCov2D(src)\n    # Use denoised src for classification\n    classification_src = DenoisedSource(src, cwf_denoiser)\n    # Peek, what do the denoised images look like...\n    if interactive:\n        classification_src.images[:10].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class Averaging\n\nNow perform classification and averaging for each class.\nThis also demonstrates the potential to use a different source for classification and averaging.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "avgs = DefaultClassAvgSource(\n    classification_src,\n    n_nbor=n_nbor,\n    averager_src=src,\n)\n# We'll continue our pipeline with the first ``n_classes`` from ``avgs``.\navgs = avgs[:n_classes].cache()\n\nif interactive:\n    avgs.images[:10].show()\n\n# Save off the set of class average images.\navgs.save(\"simulated_abinitio_pipeline_class_averages.star\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Line Estimation\n\nNext create a CL instance for estimating orientation of projections\nusing the Common Line with Synchronization Voting method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Orientation Estimation\")\n\n# Stash true rotations for later comparison.\n# Note class selection re-ordered our images, so we remap the indices back to the original source.\nindices = avgs.src.selection_indices[:n_classes]\ntrue_rotations = src.rotations[indices]\n\n# Create a custom orientation estimation object for ``avgs``.\norient_est = CLSync3N(avgs, n_theta=180)\n\n# Initialize an ``OrientedSource`` class instance that performs orientation\n# estimation in a lazy fashion upon request of images or rotations.\noriented_src = OrientedSource(avgs, orient_est)\n\nlogger.info(\"Compare with known rotations\")\n# Compare with known true rotations. ``mean_aligned_angular_distance`` globally aligns the estimated\n# rotations to the ground truth and finds the mean angular distance between them.\nmean_ang_dist = mean_aligned_angular_distance(oriented_src.rotations, true_rotations)\nlogger.info(\n    f\"Mean angular distance between globally aligned estimates and ground truth rotations: {mean_ang_dist}\\n\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume Reconstruction\n\nUsing the estimated rotations, attempt to reconstruct a volume.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Volume reconstruction\")\n\n# Setup an estimator to perform the back projection.\nestimator = MeanEstimator(oriented_src)\n\n# Perform the estimation and save the volume.\nestimated_volume = estimator.estimate()\nfn = f\"estimated_volume_n{num_imgs}_c{n_classes}_m{n_nbor}_{img_size}.mrc\"\nestimated_volume.save(fn, overwrite=True)\n\n# Peek at result\nif interactive:\n    plt.imshow(np.sum(estimated_volume.asnumpy()[0], axis=-1))\n    plt.show()\n\n# FSC with ground truth volume\nds_v = og_v.downsample(img_size)\nfsc, _ = estimated_volume.fsc(ds_v, cutoff=0.5)\nlogger.info(f\"Estimated FSC {fsc} Angstroms at {ds_v.pixel_size} Angstrom per pixel.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}