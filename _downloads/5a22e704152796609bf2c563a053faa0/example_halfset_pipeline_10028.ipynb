{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Abinitio Halfset Pipeline - Experimental Data\n\nThis demonstrates creating two half sets of experimental data,\nperforming independent reconstructions, and computing resulting FSC.\n\nSpecifically this pipeline uses the EMPIAR 10028 picked particles:\n\nhttps://www.ebi.ac.uk/empiar/EMPIAR-10028\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nfrom pathlib import Path\n\nfrom aspire.denoising import LegacyClassAvgSource\nfrom aspire.reconstruction import MeanEstimator\nfrom aspire.source import OrientedSource, RelionSource\n\nlogger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\nExample configuration.\n\nUse of GPU is expected for a large configuration.  If running on a\nless capable machine, or simply experimenting, it is strongly\nrecommended to reduce the problem size by altering ``img_size``,\n``n_classes``, ``n_nbor``, ``max_rows`` etc.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size = 179  # Downsample the images/reconstruction to a desired resolution\nn_classes = 3000  # How many class averages to compute.\nn_nbor = 50  # How many neighbors to stack\nstarfile_in = \"10028/data/shiny_2sets_fixed9.star\"\ndata_folder = \".\"  # This depends on the specific starfile entries.\npixel_size = 1.34\nfsc_cutoff = 0.143"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and split Source data\n\n``RelionSource`` is used to access the experimental data via a `STAR` file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a source object loading all the experimental images\nsrc = RelionSource(\n    starfile_in, pixel_size=pixel_size, max_rows=None, data_folder=data_folder\n)\n\n# Split the data into two sets.\n# This example uses evens and odds for simplicity, but random indices\n# can also be used with similar results.\n\nsrcA = src[::2]\nsrcB = src[1::2]\n\n# A dictionary can systematically organize our inputs and outputs for both sets.\npipelines = {\n    \"A\": {\n        \"input\": srcA,\n    },\n    \"B\": {\n        \"input\": srcB,\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dual Pipelines\nPreprocess by downsampling, correcting for CTF, and applying noise\ncorrection.  After preprocessing, class averages are generated then\nautomatically selected for use in reconstruction.\n\nEach of the above steps are performed totally independently\nfor each dataset, first for A, then for B.\n\nCaching is used throughout for speeding up large datasets on high memory machines.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for src_id, pipeline in pipelines.items():\n\n    src = pipeline[\"input\"]\n\n    # Downsample the images\n    logger.info(f\"Set the resolution to {img_size} X {img_size}\")\n    src = src.downsample(img_size).cache()\n\n    # Use phase_flip to attempt correcting for CTF.\n    logger.info(f\"Perform phase flip to {len(src)} input images for set {src_id}.\")\n    src = src.phase_flip().cache()\n\n    # Normalize the background of the images.\n    src = src.normalize_background().cache()\n\n    # Estimate the noise and whiten based on the estimated noise.\n    src = src.legacy_whiten().cache()\n\n    # Optionally invert image contrast.\n    logger.info(\"Invert the global density contrast\")\n    src = src.invert_contrast().cache()\n\n    # Now perform classification and averaging for each class.\n    logger.info(\"Begin Class Averaging\")\n\n    avgs = LegacyClassAvgSource(src, n_nbor=n_nbor)\n    avgs = avgs[:n_classes].cache()\n\n    # Common Line Estimation\n    logger.info(\"Begin Orientation Estimation\")\n    oriented_src = OrientedSource(avgs)\n\n    # Volume Reconstruction\n    logger.info(\"Begin Volume reconstruction\")\n\n    # Setup an estimator to perform the back projection.\n    estimator = MeanEstimator(oriented_src)\n\n    # Perform the estimation and save the volume.\n    pipeline[\"volume_output_filename\"] = fn = (\n        f\"10028_abinitio_c{n_classes}_m{n_nbor}_{img_size}px_{src_id}.mrc\"\n    )\n    estimated_volume = estimator.estimate()\n    estimated_volume.save(fn, overwrite=True)\n    logger.info(f\"Saved Volume to {str(Path(fn).resolve())}\")\n\n    # Store volume result in pipeline dict.\n    pipeline[\"estimated_volume\"] = estimated_volume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute FSC Score\nAt this point both pipelines have completed reconstructions and may be compared using FSC.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Recall our resulting volumes from the dictionary.\nvol_a = pipelines[\"A\"][\"estimated_volume\"]\nvol_b = pipelines[\"B\"][\"estimated_volume\"]\n\n# Compute the FSC\n# Save plot, in case display is not available.\nvol_a.fsc(vol_b, cutoff=fsc_cutoff, plot=\"fsc_plot.png\")\n# Display plot and report\nfsc, _ = vol_a.fsc(vol_b, cutoff=fsc_cutoff, plot=True)\nlogger.info(\n    f\"Found FSC of {fsc} Angstrom at cutoff={fsc_cutoff} and pixel size {vol_a.pixel_size} Angstrom/pixel.\"\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}