{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Abinitio Pipeline - Experimental Data EMPIAR 10028\n\nThis notebook introduces a selection of\ncomponents corresponding to loading real Relion picked\nparticle cryo-EM data and running key ASPIRE-Python\nab initio model components as a pipeline.\n\nThis demonstrates reproducing results similar to those found in:\n\n.. admonition:: Publication\n\n   | Common lines modeling for reference free Ab-initio reconstruction in cryo-EM\n   | Journal of Structural Biology 2017\n   | https://doi.org/10.1016/j.jsb.2017.09.007\n\nSpecifically this pipeline uses the\nEMPIAR 10028 picked particles data, available here:\n\nhttps://www.ebi.ac.uk/empiar/EMPIAR-10028\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\nImport packages that will be used throughout this experiment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nfrom pathlib import Path\n\nfrom aspire.denoising import LegacyClassAvgSource\nfrom aspire.reconstruction import MeanEstimator\nfrom aspire.source import OrientedSource, RelionSource\n\nlogger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n\nUse of GPU is expected for a large configuration.\nIf running on a less capable machine, or simply experimenting, it is\nstrongly recommended to reduce ``img_size``, ``n_imgs``, and\n``n_nbor``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Inputs\n# Note the published ``shiny_2sets.star`` requires removal of a stray '9' character on line 5476.\nstarfile_in = \"10028/data/shiny_2sets_fixed9.star\"\ndata_folder = \".\"  # This depends on the specific starfile entries.\npixel_size = 1.34  # Defined with the dataset from EMPIAR\n\n# Config\nn_imgs = None  # Set to None for all images in starfile, can set smaller for tests.\nimg_size = 179  # Downsample the images/reconstruction to a desired resolution\nn_classes = 3000  # How many class averages to compute.\nn_nbor = 50  # How many neighbors to stack\n\n# Outputs\npreprocessed_fn = f\"10028_preprocessed_{img_size}px.star\"\nclass_avg_fn = f\"10028_var_sorted_cls_avgs_m{n_nbor}_{img_size}px.star\"\noriented_fn = f\"10028_oriented_class_averages_{img_size}px.star\"\nvolume_output_filename = f\"10028_abinitio_c{n_classes}_m{n_nbor}_{img_size}px.mrc\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Source data and Preprocessing\n\n``RelionSource`` is used to access the experimental data via a `STAR` file.\nBegin by preprocessing to correct for CTF, then downsample to ``img_size``\nand apply noise correction.\n\nASPIRE-Python has the ability to automatically adjust CTF filters\nfor downsampling, and this can be employed simply by changing the\norder of preprocessing steps, saving time by phase flipping lower\nresolution images.  However, this script intentionally follows the\norder described in the original publication.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a source object for the experimental images\nsrc = RelionSource(\n    starfile_in, pixel_size=pixel_size, max_rows=n_imgs, data_folder=data_folder\n)\n\n# Use phase_flip to attempt correcting for CTF.\n# Caching is used throughout for speeding up large datasets on high memory machines.\nlogger.info(\"Perform phase flip to input images.\")\nsrc = src.phase_flip().cache()\n\n# Legacy MATLAB cropped the images to an odd resolution.\nsrc = src.crop_pad(src.L - 1).cache()\n\n# Downsample the images.\nlogger.info(f\"Set the resolution to {img_size} X {img_size}\")\nsrc = src.legacy_downsample(img_size).cache()\n\n# Normalize the background of the images.\nsrc = src.legacy_normalize_background().cache()\n\n# Estimate the noise and whiten based on the estimated noise.\nsrc = src.legacy_whiten().cache()\n\n# Optionally invert image contrast.\nlogger.info(\"Invert the global density contrast\")\nsrc = src.invert_contrast().cache()\n\n# Save the preprocessed images.\n# These can be reused to experiment with later stages of the pipeline\n# without repeating the preprocessing computations.\nsrc.save(preprocessed_fn, save_mode=\"single\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class Averaging\n\nNow perform classification and averaging for each class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Class Averaging\")\navgs = LegacyClassAvgSource(src, n_nbor=n_nbor).cache()\n\n# Save the entire set of class averages to disk so they can be re-used.\navgs.save(class_avg_fn, save_mode=\"single\", overwrite=True)\n\n# We'll continue our pipeline with the first ``n_classes`` from\n# ``avgs``.  The classes will be selected by the ``class_selector`` of a\n# ``ClassAvgSource``, which in this case will be the class averages\n# having the largest variance.  Note global sorting requires computing\n# all class averages, which is computationally intensive.\navgs = avgs[:n_classes].cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Line Estimation\n\nEstimate orientation of projections and assign to source by\napplying ``OrientedSource`` to the class averages from the prior\nstep. By default this applies the Common Line with Synchronization\nVoting ``CLSync3N`` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Orientation Estimation\")\noriented_src = OrientedSource(avgs)\n\n# Save off the selected set of class average images, along with the\n# estimated orientations and shifts.  These can be reused to\n# experiment with alternative volume reconstructions.\noriented_src.save(oriented_fn, save_mode=\"single\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume Reconstruction\n\nUsing the oriented source, attempt to reconstruct a volume.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Volume reconstruction\")\n\n# Set up an estimator to perform the backprojection.\nestimator = MeanEstimator(oriented_src)\n\n# Perform the estimation and save the volume.\nestimated_volume = estimator.estimate()\nestimated_volume.save(volume_output_filename, overwrite=True)\nlogger.info(f\"Saved Volume to {str(Path(volume_output_filename).resolve())}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}