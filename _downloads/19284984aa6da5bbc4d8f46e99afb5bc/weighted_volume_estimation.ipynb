{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Weighted Volume Reconstruction\n\nThis tutorial demonstrates a weighted volume reconstruction,\nusing a published reference dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download an Example Dataset\nASPIRE's downloader will download, cache,\nand unpack the reference dataset.\nMore information about the dataset can be found on\n[Zenodo](https://zenodo.org/records/8186548)\nand in this [paper](https://iopscience.iop.org/article/10.1088/1361-6420/ab4f55/ampdf)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire import downloader\n\nsim_data = downloader.simulated_channelspin()\n\n# This data contains a `Volume` stack, an `Image` stack, weights and\n# corresponding parameters that were used to derive images\n# from the volumes.  For example, the rotations below are the known\n# true simulation projection rotations. In practice these would be\n# derived from an orientation estimation component.\n\nimgs = sim_data[\"images\"]  # Simulated image stack (`Image` object)\nrots = sim_data[\"rots\"]  # True projection rotations (`Rotation` object)\nweights = sim_data[\"weights\"]  # Volume weights (`Numpy` array)\nvols = sim_data[\"vols\"]  # True reference volumes (`Volume` object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a ``ImageSource``\nThe image stack and projection rotation (Euler) angles can be\nassociated together during instantiation of an ``ImageSource``.\nBecause this example starts with a dense array of images,\nan ``ArrayImageSource`` is used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.source import ArrayImageSource\n\nsrc = ArrayImageSource(imgs, angles=rots.angles)\n\n# The images are downsampled for the sake of a quicker tutorial.\n# This line can be commented out to achieve the reference size (54 pixels).\nsrc = src.downsample(24)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This tutorial demonstrates bringing reference data.\n    It is also possible to just create a ``Simulation`` or use other\n    ``ImageSource`` objects, so long as the rotations required\n    for backprojecting are assigned.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume Reconstruction\nPerforming a weighted volume reconstruction requires defining an\nappropriate 3D basis and supplying an associated image to volume\nweight mapping as an array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.basis import FFBBasis3D\nfrom aspire.reconstruction import WeightedVolumesEstimator\n\n# Create a reasonable Basis\nbasis = FFBBasis3D(src.L, dtype=src.dtype)\n\n# Set up an estimator to perform the backprojections and volume estimation.\n# In this case, the `weights` array comes from the reference data set,\n# and is shaped to map images to spectral volumes.\n# Note that we can have many more actual/reference volumes generating\n# the image stack than spectral volumes.  In this case the input\n# images were generated from 54 volumes, but are described by 16\n# spectral volumes.\nprint(\"`weights shape:`\", weights.shape)\nestimator = WeightedVolumesEstimator(weights, src, basis, preconditioner=\"none\")\n\n# Perform the estimation, returning a `Volume` stack.\nestimated_volume = estimator.estimate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The ``estimate()`` method requires a fair amount of compute time,\n    but there should be regularly logged progress towards convergence.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of Estimated Volume with Source Volume\nGenerate several random projections rotations, then compare these\nprojections between the estimated spectral volumes and a known volume.\nIf ``src`` was downsampled above, the resulting estimated volumes\nand projections will be of similar downsampled quality.\n\nNote that the estimated spectral volumes are treated as `Volume`\nobjects purely for convienience and are not expected to correspond\nexactly to any particular reference volume.  The spectral volumes\ncollectively describe motion features derived from the input data.\nHowever, basic visual comparison is useful as a sanity check to\ndemonstrate that we are in fact generating spectral volumes that\nappear reasonably similar to the input volumes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.utils import Rotation\n\nreference_v = 0  # Actual volume under comparison\nspectral_v = 0  # Estimated spectral volume\nm = 3  # Number of projections\n\nrandom_rotations = Rotation.generate_random_rotations(m, dtype=src.dtype)\n\n# Estimated volume projections\nestimated_volume[spectral_v].project(random_rotations).show()\n\n# Source volume projections\nvols[reference_v].project(random_rotations).show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}