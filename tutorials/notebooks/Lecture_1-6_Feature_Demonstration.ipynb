{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polar-appeal",
   "metadata": {},
   "source": [
    "# ASPIRE-Python Introduction\n",
    "\n",
    "In this notebook we will introduce some code from ASPIRE-Python that corresponds to topics from MATH586.\n",
    "\n",
    "First I'll import some of the usual suspects, and we'll import classes from ASPIRE as we use them.\n",
    "\n",
    "### Homework Task 0\n",
    "Attempt to install ASPIRE on your machine.  ASPIRE can generally install on Linux, Mac, and Windows under Anaconda Python, by following the instructions in the README.  [The instructions for developers is the most comprehensive](https://github.com/ComputationalCryoEM/ASPIRE-Python/blob/master/README.md#for-developers).  Linux is the most tested platform.\n",
    "\n",
    "ASPIRE requires some resources to run, so if you wouldn't run typical data science codes on your machine (maybe a netbook for example), you may use TigerCPU.  After logging into TigerCPU, `module load anaconda3/2020.7` and follow the anaconda instructions for developers in the link above. Those instructions should create a working environment for tinkering with ASPIRE code found in this notebook.\n",
    "\n",
    "As a last resort, this code can be run in your browser via `binder`, but out of the box this will limit you to included sample datasets.  [Run this notebook on mybinder.com](https://mybinder.org/v2/gh/ComputationalCryoEM/ASPIRE-Python/master?filepath=tutorials/notebooks/Lecture_1-6_Feature_Demonstration.ipynb)  (This may take a few minutes to launch container.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-appearance",
   "metadata": {},
   "source": [
    "## `Image` Class\n",
    "\n",
    "The [Image](https://computationalcryoem.github.io/ASPIRE-Python/aspire.image.html#aspire.image.image.Image) class is a thin wrapper over numpy arrays for a stack containing 1 or more images.  In this notebook we won't be working directly with the `Image` class a lot, but it will be one of the fundemental structures behind the scenes.  A lot of ASPIRE code passes around `Image` and `Volume` classes.\n",
    "\n",
    "Examples of using the Image class can be found in:\n",
    "- `examples/basic_image_array.py`\n",
    "- `tutorials/notebooks/00_image_class.ipynb`\n",
    "\n",
    "## `Volume` Class\n",
    "\n",
    "Like `Image`, the [Volume](https://computationalcryoem.github.io/ASPIRE-Python/aspire.volume.html#aspire.volume.Volume) class is a thin wrapper over numpy arrays that provides specialized methods for a stack containing 1 or more volumes.\n",
    "\n",
    "Here we will instantiate a Volume using a numpy array and use it to downsample to a desired resolution (64 should be good).  For the data source I chose to download a real volume density map from EMDB https://www.ebi.ac.uk/pdbe/entry/emdb/EMD-2660. The download was uncompressed in my local directory.  The notebook defaults to a small low resolution sample file you may use to sanity check.  Unfortunately real data can be quite large so we do not ship it with the repo.\n",
    "\n",
    "#### Homework Task 1\n",
    "\n",
    "- Starting from [EMPIAR](https://www.ebi.ac.uk/pdbe/emdb/empiar/) find a molecule of interest and try to find if it has a corresponding volume density map from [EMDB](https://www.ebi.ac.uk/pdbe/emdb).\n",
    "- Download such a map and use it in the following experiments where I have used 2660.\n",
    "\n",
    "##### Helpful friendly hint: \n",
    "`mrcfile` will typically open `.map` files provided by EMDB, corresponding to an EMPIAR entry. This was not obvious to me, but you may [read more about the format here](https://www.emdataresource.org/mapformat.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.volume import Volume\n",
    "\n",
    "# A low res example file is included in the repo as a sanity check.\n",
    "infile = mrcfile.open(\"../../tutorials/data/clean70SRibosome_vol_65p.mrc\")\n",
    "\n",
    "# More interesting data requires downloading locally.\n",
    "# infile = mrcfile.open(\"EMD-2660/map/emd_2660.map\")\n",
    "\n",
    "d = infile.data\n",
    "print(f\"map data shape: {d.shape} dtype:{d.dtype}\")\n",
    "v = Volume(d)\n",
    "\n",
    "# Downsample the volume to a desired resolution\n",
    "img_size = 64\n",
    "# Volume.downsample() Returns a new Volume instance.\n",
    "#   We will use this lower resolution volume later.\n",
    "v2 = v.downsample((img_size, img_size, img_size))\n",
    "L = v2.resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-parent",
   "metadata": {},
   "source": [
    "We can make some quick plots to peek at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, for quick sanity checking purposes we can view as a contour plot.\n",
    "#   We'll use three orthographic projections, one per axis.\n",
    "for axis in range(3):\n",
    "    plt.contourf(np.arange(L),np.arange(L), np.sum(v2[0], axis=axis))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can attempt a 3d Scatter plot, but the results aren't very good.\n",
    "x, y, z = np.meshgrid(np.arange(L), np.arange(L), np.arange(L))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(x,y,z, c=np.log10(v2.flatten()), cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-helicopter",
   "metadata": {},
   "source": [
    "### Homework Task 2\n",
    "\n",
    "Above I have used a simple log transform with a scatter plot to peek at the 3D data. \n",
    "This was mainly just to make sure the data was in the neighborhood of what I was looking for.\n",
    "More commonly we will want to construct an `isosurface` plot.\n",
    "Try to create a better plot of the volume ( this will probably require more advanced tools than matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-translator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "simplified-topic",
   "metadata": {},
   "source": [
    "## `Rotation` Class - Generating Random Rotations\n",
    "\n",
    "To get general projections this brings us to generating random rotations which we will apply to our volume.\n",
    "\n",
    "While you may bring your own 3x3 matrices or generate manually (say from your own Euler angles),\n",
    "ASPIRE has a [Rotation class](https://computationalcryoem.github.io/ASPIRE-Python/aspire.utils.html#module-aspire.utils.rotation) which can do this random rotation generation for us.  It also has some other utility methods if you would want to compare with something manual.\n",
    "\n",
    "The following code will generate some random rotations, and use the `Volume.project()` method to return an `Image` instance representing the stack of projections.  We can display projection images using the `Image.show()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.utils.rotation import Rotation\n",
    "\n",
    "num_rotations = 2\n",
    "rots = Rotation.generate_random_rotations(n=num_rotations, seed=12345)\n",
    "\n",
    "# We can access the numpy array holding the actual stack of 3x3 matrices:\n",
    "print(rots)\n",
    "print(rots.matrices)\n",
    "\n",
    "# Using the first(and in this case, only) volume, compute projections using the stack of rotations:\n",
    "projections = v.project(0, rots)\n",
    "\n",
    "# project() returns an Image instance.\n",
    "print(projections)\n",
    "projections.show()\n",
    "# Neat, we've generated random projections of some real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-memorabilia",
   "metadata": {},
   "source": [
    "## The `source` Package\n",
    "\n",
    "[aspire.source](https://computationalcryoem.github.io/ASPIRE-Python/aspire.source.html#module-aspire.source.simulation) package contains a collection of data source interfaces.\n",
    "The idea is that we can design an experiment using a synthetic `Simulation` source or our own provided array via `ArrayImageSource`; then later swap out the source for a large experimental data set using something like `RelionSource`.\n",
    "\n",
    "We do this because the experimental datasets are too large to fit in memory. They cannot be provided as a massive large array, and instead require methods to orchestrate batching. Depending on the application, they may also require corresponding batched algorithms.  The `Source` classes try to make most of this opaque to an end user.  Ideally we can swap one source for another.\n",
    "\n",
    "For now we will build up to the creation and application of synthetic data set based on the real volume data used previously.\n",
    "\n",
    "## `Simulation` Class\n",
    "\n",
    "Generating realistic synthetic data sources is a common task.\n",
    "The process of generating then projecting random rotations is integrated into the [Simulation](https://computationalcryoem.github.io/ASPIRE-Python/aspire.source.html#module-aspire.source.simulation) class.\n",
    "Using `Simulation`, we can generate arbitrary numbers of projections for use in experiments.\n",
    "Later we will demonstrate additional features which allow us to create more realistic data sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.source import Simulation\n",
    "\n",
    "num_imgs = 100  # How many images in our source.\n",
    "# Generate a Simulation instance based on the original volume data.\n",
    "sim = Simulation(L=v.resolution, n=num_imgs, vols=v)\n",
    "# Display the first 10 images\n",
    "sim.images(0, 10).show()  # Hi Res\n",
    "\n",
    "# Repeat for the lower resolution (downsampled) volume v2.\n",
    "sim2 = Simulation(L=v2.resolution, n=num_imgs, vols=v2)\n",
    "sim2.images(0, 10).show()  # Lo Res\n",
    "\n",
    "# Note both of those simulations have the same rotations\n",
    "#   because they had the same seed by default,\n",
    "# We can set our own seed to get a different random samples (of rotations).\n",
    "sim_seed = Simulation(L=v.resolution, n=num_imgs, vols=v, seed=42)\n",
    "sim_seed.images(0, 10).show()\n",
    "\n",
    "# We can also view the rotations used to create these projections\n",
    "# print(sim2.rots)  # Commented due to long output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-dispute",
   "metadata": {},
   "source": [
    "## Simulation with Noise - Filters\n",
    "\n",
    "### Filters\n",
    "\n",
    "[Filters](https://computationalcryoem.github.io/ASPIRE-Python/aspire.operators.html#module-aspire.operators.filters) are a collection of classes which once configured can be applied to `Source` pipelines.  Common filters we might use are `ScalarFilter`, `PowerFilter`, `FunctionFilter`, and `CTFFilter`.\n",
    "\n",
    "### Adding to Simulation\n",
    "\n",
    "We can customize Sources by adding stages to their generation pipeline.\n",
    "In this case of a Simulation source, we want to corrupt the projection images with significant noise.\n",
    "\n",
    "First we create a constant two dimension filter (constant value set to our desired noise variance).\n",
    "Then when used in the `noise_filter`, this scalar will be multiplied by a random sample.\n",
    "Similar to before, if you require a different sample, this would be controlled via a `seed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.operators import ScalarFilter\n",
    "\n",
    "# Using the sample variance, we'll compute a target noise variance\n",
    "var = np.var(sim2.images(0, sim2.n).asnumpy())\n",
    "print(f\"sim2 clean sample var {var}\")\n",
    "noise_variance = 100. * var\n",
    "print(f\"noise var {noise_variance}\")\n",
    "\n",
    "# Then create a constant filter based on that variance\n",
    "white_noise_filter = ScalarFilter(dim=2, value=noise_variance)\n",
    "# We can create a similar simulation with this additional noise_filter argument:\n",
    "sim3 = Simulation(L=v2.resolution, n=num_imgs, vols=v2, noise_filter=white_noise_filter)\n",
    "sim3.images(0, 10).show()\n",
    "# These should be rather noisy now ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-austria",
   "metadata": {},
   "source": [
    "## Common Line Estimation\n",
    "\n",
    "Now we can create a CL instance for estimating orientation of projections using the Common Line with synchronization method.\n",
    "\n",
    "We will import [CLSyncVoting](https://computationalcryoem.github.io/ASPIRE-Python/aspire.abinitio.html?highlight=clsyncvoting#aspire.abinitio.commonline_sync.CLSyncVoting), then several helper utilities fron the `coor_trans` package to help verify our estimates.\n",
    "\n",
    "For each iteration in the loop:\n",
    "- Save the true rotations\n",
    "- Compute orientation estimate using CLSyncVoting method\n",
    "- Compare the estimated vs true rotations\n",
    "\n",
    "Each iteration will print some diagnostic information that contains the top eigenvalues found.\n",
    "From class we learned that a healthy eigen distribution should have a significant gap after the third eigenvalue.\n",
    "It is clear we have such eigenspacing for the clean images, but not for the noisy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.abinitio import CLSyncVoting\n",
    "from aspire.utils.coor_trans import (\n",
    "    get_aligned_rotations,\n",
    "    get_rots_mse,\n",
    "    register_rotations,\n",
    ")\n",
    "\n",
    "for desc, _sim in [('High Res', sim),\n",
    "                  ('Downsampled', sim2),\n",
    "                  ('Downsampled with Noise', sim3)]:\n",
    "    print(desc)\n",
    "    true_rotations = _sim.rots  # for later comparison\n",
    "    \n",
    "    orient_est = CLSyncVoting(_sim, n_theta=36)    \n",
    "    # Get the estimated rotations\n",
    "    orient_est.estimate_rotations()    \n",
    "    rots_est = orient_est.rotations\n",
    "    \n",
    "    # Compare with known true rotations\n",
    "    Q_mat, flag = register_rotations(rots_est, true_rotations)\n",
    "    regrot = get_aligned_rotations(rots_est, Q_mat, flag)\n",
    "    mse_reg = get_rots_mse(regrot, true_rotations)\n",
    "    print(f\"MSE deviation of the estimated rotations using register_rotations : {mse_reg}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-objective",
   "metadata": {},
   "source": [
    "#### Homework Task 3\n",
    "\n",
    "We confirmed a dramatic change in the eigen spacing when we add a lot of noise.\n",
    "Compute the SNR in this case using the formula described from class.\n",
    "Repeat the experiment with varying levels of SNR to find at what level the character of the eigen spacing changes.\n",
    "This will require changing the Simulation Source's noise_filter.\n",
    "How does this compare with the levels discussed in lecture?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-screening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unique-superior",
   "metadata": {},
   "source": [
    "## More Advanced Noise - Whitening\n",
    "\n",
    "We can estimate the noise across the stack of images\n",
    "\n",
    "### The `noise` Package\n",
    "\n",
    "The [aspire.noise](https://computationalcryoem.github.io/ASPIRE-Python/aspire.noise.html) package contains several useful classes for generating and estimating different types of noise.  \n",
    "\n",
    "In this case, we know the noise to be white, so we can proceed directly to [WhiteNoiseEstimator](https://computationalcryoem.github.io/ASPIRE-Python/aspire.noise.html#aspire.noise.noise.WhiteNoiseEstimator).  The noise estimators consume from a `Source`.\n",
    "\n",
    "The white noise estimator should log a diagnostic variance value. How does this compare with the known noise variance above?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.noise import WhiteNoiseEstimator\n",
    "\n",
    "# Create another Simulation source to tinker with.\n",
    "sim_wht = Simulation(L=v2.resolution, n=num_imgs, vols=v2, noise_filter=white_noise_filter)\n",
    "\n",
    "# Estimate the white noise.\n",
    "noise_estimator = WhiteNoiseEstimator(sim_wht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-saturn",
   "metadata": {},
   "source": [
    "\n",
    "### A Custom `FunctionFilter`\n",
    "\n",
    "We will now apply some more interesting noise, using a custom function, and then apply a `whitening` process to our data.\n",
    "\n",
    "Using `FunctionFilter` we can create our own custom functions to apply in a pipeline.\n",
    "Here we want to apply a custom filter as a noise adder.  We can use a function of two variables for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.operators import FunctionFilter\n",
    "\n",
    "def noise_function(x, y):\n",
    "    return 1E-7 * np.exp(-(x * x + y * y) / (2 * 0.3 ** 2))\n",
    "\n",
    "# In python, functions are first class objects.\n",
    "# We take advantage of that to pass this function around as a variable.\n",
    "# It will be evaluated later...\n",
    "custom_noise_filter = FunctionFilter(noise_function)\n",
    "\n",
    "# Create yet another Simulation source to tinker with.\n",
    "sim4 = Simulation(L=v2.resolution, n=num_imgs, vols=v2, noise_filter=custom_noise_filter)\n",
    "sim4.images(0,10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-career",
   "metadata": {},
   "source": [
    "\n",
    "Applying the `Simulation.whiten()` method just requires passing the filter corresponding to the estimated noise instance. Then we can inspect some of the whitened images.  While noise is still present, we can see a dramatic change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.noise import AnisotropicNoiseEstimator\n",
    "\n",
    "# Estimate noise.\n",
    "aiso_noise_estimator = AnisotropicNoiseEstimator(sim4)\n",
    "\n",
    "# Whiten based on the estimated noise\n",
    "sim4.whiten(aiso_noise_estimator.filter)\n",
    "\n",
    "# What do the whitened images look like...\n",
    "sim4.images(0,10).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-cowboy",
   "metadata": {},
   "source": [
    "### Homework Task 4\n",
    "\n",
    "Try some other image preprocessing methods exposed by the `Simulation`/`ImageSource` classes.\n",
    "\n",
    "Try some other custom function to add noise or other corruptions to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-player",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cordless-academy",
   "metadata": {},
   "source": [
    "## Real Experimental Data - `RelionSource`\n",
    "Now that we know our experiment code seems to run,\n",
    "we can try to replace the simulation with a real experimental data source.\n",
    "\n",
    "Lets attempt the same CL experiment, but with a `RelionSource`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.source import RelionSource\n",
    "\n",
    "src =  RelionSource(\n",
    "    \"../../tests/saved_test_data/sample_relion_data.star\", data_folder=\"\", pixel_size=5.0, max_rows=1024\n",
    ")\n",
    "\n",
    "# Data resides on Tiger Cluster\n",
    "# Please make sure you are using a compute node once you've installed ASPIRE, not the head node...\n",
    "#src =  RelionSource(\n",
    "#    \"/tigress/gbwright/data/cryo-em/CryoEMdata/empiar10028/shiny_2sets.star\", data_folder=\"\", pixel_size=5.0, max_rows=100\n",
    "#) \n",
    "src.downsample(img_size)\n",
    "\n",
    "src.images(0,10).show()\n",
    "\n",
    "noise_estimator = WhiteNoiseEstimator(src)\n",
    "src.whiten(noise_estimator.filter)\n",
    "\n",
    "orient_est = CLSyncVoting(src, n_theta=36)\n",
    "orient_est.estimate_rotations()\n",
    "rots_est = orient_est.rotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-attachment",
   "metadata": {},
   "source": [
    "We can see that the code can easily run with experimental data by subsituting the `Source` class. However, we have hit the practical limitation that requires class averaging of images...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-minnesota",
   "metadata": {},
   "source": [
    "## CTF Filter\n",
    "\n",
    "Here we can use the `RadialCTFFilter` subclass of [CTFFilter](https://computationalcryoem.github.io/ASPIRE-Python/aspire.operators.html?highlight=ctffilter#aspire.operators.filters.CTFFilter) to generate some simulated images with CTF effects.\n",
    "\n",
    "We use the `unique_filter` argument of the `Simulation` class to apply a collection of several CTFs with different defocus. The defocus values are generated from the `np.linspace` method. We end up with a list of filters.\n",
    "\n",
    "By combining CTFFilters, noise, and other filters ASPIRE can generate repeatable rich data sets with controlled parameters.  The `Simulation` class will attempt to apply transforms `on the fly` to batches of our images, allowing us to generate arbitrarily long stacks of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspire.operators import RadialCTFFilter\n",
    "\n",
    "# Specify the CTF parameters not used for this example\n",
    "# but necessary for initializing the simulation object\n",
    "pixel_size = 5  # Pixel size of the images (in angstroms)\n",
    "voltage = 200  # Voltage (in KV)\n",
    "defocus_min = 1.5e4  # Minimum defocus value (in angstroms)\n",
    "defocus_max = 2.5e4  # Maximum defocus value (in angstroms)\n",
    "defocus_ct = 7  # Number of defocus groups.\n",
    "Cs = 2.0  # Spherical aberration\n",
    "alpha = 0.1  # Amplitude contrast\n",
    "\n",
    "# Initialize simulation object with CTF filters.\n",
    "# Create CTF filters\n",
    "filters = [\n",
    "    RadialCTFFilter(pixel_size, voltage, defocus=d, Cs=2.0, alpha=0.1)\n",
    "    for d in np.linspace(defocus_min, defocus_max, defocus_ct)\n",
    "]\n",
    "\n",
    "sim5 = Simulation(L=v2.resolution, n=num_imgs, vols=v2, unique_filters=filters)\n",
    "sim5.images(0, 10).show()\n",
    "\n",
    "\n",
    "# Here we will combine CTF and noise features to our projections.\n",
    "sim6 = Simulation(L=v2.resolution, n=num_imgs, vols=v2, unique_filters=filters, noise_filter=custom_noise_filter)\n",
    "sim6.images(0, 10).show()\n",
    "\n",
    "# Estimate noise.\n",
    "aiso_noise_estimator = AnisotropicNoiseEstimator(sim6)\n",
    "\n",
    "# Whiten based on the estimated noise\n",
    "sim6.whiten(aiso_noise_estimator.filter)\n",
    "sim6.images(0, 10).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-worship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
